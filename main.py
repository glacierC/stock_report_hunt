#!/usr/bin/env python3
"""
è´¢æŠ¥ä¸‹è½½å·¥å…· v0.3 - ä¸‹è½½SECè´¢æŠ¥å’ŒEarnings Call Transcript
"""

import argparse
import os
import re
import subprocess
import sys
from pathlib import Path

import requests
from bs4 import BeautifulSoup
from markdownify import markdownify as md


# SEC API è¦æ±‚è®¾ç½® User-Agent
HEADERS = {
    "User-Agent": os.environ.get("SEC_USER_AGENT", "MyApp contact@example.com"),
    "Accept-Encoding": "gzip, deflate",
}


def get_cik(ticker: str) -> str:
    """é€šè¿‡ ticker è·å–å…¬å¸ CIK"""
    url = "https://www.sec.gov/cgi-bin/browse-edgar"
    params = {
        "action": "getcompany",
        "CIK": ticker,
        "type": "10-K",
        "dateb": "",
        "owner": "include",
        "count": 1,
        "output": "atom",
    }
    resp = requests.get(url, params=params, headers=HEADERS)
    resp.raise_for_status()

    # ä» Atom feed ä¸­æå– CIK
    match = re.search(r"CIK=(\d+)", resp.text)
    if not match:
        raise ValueError(f"æ— æ³•æ‰¾åˆ° {ticker} çš„ CIK")
    return match.group(1)


def get_latest_filing(cik: str, form_type: str) -> dict | None:
    """è·å–æœ€æ–°çš„æŒ‡å®šç±»å‹ filing ä¿¡æ¯"""
    cik_padded = cik.zfill(10)
    url = f"https://data.sec.gov/submissions/CIK{cik_padded}.json"

    resp = requests.get(url, headers=HEADERS)
    resp.raise_for_status()
    data = resp.json()

    filings = data.get("filings", {}).get("recent", {})
    forms = filings.get("form", [])
    accessions = filings.get("accessionNumber", [])
    primary_docs = filings.get("primaryDocument", [])
    filing_dates = filings.get("filingDate", [])

    for i, form in enumerate(forms):
        if form == form_type:
            return {
                "accession": accessions[i].replace("-", ""),
                "accession_display": accessions[i],
                "primary_document": primary_docs[i],
                "filing_date": filing_dates[i],
            }
    return None


def download_primary_document(cik: str, filing: dict) -> str:
    """ä¸‹è½½ä¸»æ–‡æ¡£ HTML å†…å®¹"""
    accession = filing["accession"]
    primary_doc = filing["primary_document"]

    url = f"https://www.sec.gov/Archives/edgar/data/{cik}/{accession}/{primary_doc}"
    print(f"  ä¸‹è½½: {url}")

    resp = requests.get(url, headers=HEADERS)
    resp.raise_for_status()
    return resp.text


def html_to_markdown(html_content: str) -> str:
    """å°† HTML è½¬æ¢ä¸ºå¹²å‡€çš„ Markdown"""
    soup = BeautifulSoup(html_content, "html.parser")

    # ç§»é™¤ä¸éœ€è¦çš„å…ƒç´ 
    for tag in soup.find_all(["script", "style", "meta", "link", "noscript"]):
        tag.decompose()

    # ç§»é™¤éšè—å…ƒç´ 
    for tag in soup.find_all(style=re.compile(r"display:\s*none", re.I)):
        tag.decompose()

    # è½¬æ¢ä¸º Markdown
    markdown = md(str(soup), heading_style="ATX", bullets="-")

    # æ¸…ç†å¤šä½™ç©ºè¡Œ
    markdown = re.sub(r"\n{3,}", "\n\n", markdown)

    return markdown.strip()


def download_and_convert(ticker: str, download_dir: Path) -> tuple[Path, list[dict]]:
    """ä¸‹è½½å¹¶è½¬æ¢è´¢æŠ¥ï¼Œè¿”å› (ç›®å½•è·¯å¾„, æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨)"""
    print(f"æ­£åœ¨å¤„ç† {ticker}...")

    # è·å– CIK
    print("  è·å–å…¬å¸ CIK...")
    cik = get_cik(ticker)
    print(f"  CIK: {cik}")

    # åˆ›å»ºä¸‹è½½ç›®å½•
    ticker_dir = download_dir / ticker
    ticker_dir.mkdir(parents=True, exist_ok=True)

    downloaded_files = []

    # å°è¯•è·å– 10-K å’Œ 10-Q
    for form_type in ["10-K", "10-Q"]:
        print(f"  æŸ¥æ‰¾æœ€æ–° {form_type}...")
        filing = get_latest_filing(cik, form_type)

        if not filing:
            print(f"  æœªæ‰¾åˆ° {form_type}")
            continue

        print(f"  æ‰¾åˆ° {form_type} ({filing['filing_date']})")

        # ä¸‹è½½ä¸»æ–‡æ¡£
        html_content = download_primary_document(cik, filing)

        # è½¬æ¢ä¸º Markdown
        print("  è½¬æ¢ä¸º Markdown...")
        markdown = html_to_markdown(html_content)

        # ä¿å­˜æ–‡ä»¶
        output_file = ticker_dir / f"{ticker}_{form_type}_{filing['filing_date']}.md"
        output_file.write_text(markdown, encoding="utf-8")
        print(f"  å·²ä¿å­˜: {output_file.name}")

        downloaded_files.append({
            "type": form_type,
            "date": filing["filing_date"],
            "filename": output_file.name,
        })

    return ticker_dir, downloaded_files


def open_folder(folder_path: Path) -> None:
    """æ‰“å¼€æ–‡ä»¶å¤¹ (macOS)"""
    if folder_path.exists():
        subprocess.run(["open", str(folder_path)])
        print(f"\nå·²æ‰“å¼€æ–‡ä»¶å¤¹: {folder_path}")
    else:
        print(f"\nè­¦å‘Š: æ–‡ä»¶å¤¹ä¸å­˜åœ¨ {folder_path}")


def show_prompt() -> None:
    """æ˜¾ç¤º my_prompt.txt çš„å†…å®¹"""
    prompt_file = Path("my_prompt.txt")
    if prompt_file.exists():
        print("\n" + "=" * 50)
        print("åˆ†ææç¤º:")
        print("=" * 50)
        print(prompt_file.read_text())
    else:
        print("\næç¤º: æœªæ‰¾åˆ° my_prompt.txt æ–‡ä»¶")


def print_report_summary(sec_files: list[dict], earnings_date: str | None):
    """æ‰“å°æŠ¥å‘Šæ—¶é—´æ‘˜è¦"""
    print("\n" + "=" * 50)
    print("ğŸ“… æŠ¥å‘Šæ—¶é—´æ‘˜è¦")
    print("=" * 50)

    if sec_files:
        for f in sec_files:
            print(f"  {f['type']:6} å‘å¸ƒæ—¥æœŸ: {f['date']}")

    if earnings_date:
        print(f"  Earnings Call æ—¥æœŸ: {earnings_date}")

    if not sec_files and not earnings_date:
        print("  (æ— æŠ¥å‘Šä¿¡æ¯)")

    print("=" * 50)


def main():
    parser = argparse.ArgumentParser(description="ä¸‹è½½SECè´¢æŠ¥å’ŒEarnings Call")
    parser.add_argument("ticker", help="è‚¡ç¥¨ä»£ç  (å¦‚ NVDA, AAPL)")
    parser.add_argument("--earnings", "-e", action="store_true",
                        help="ä¸‹è½½ Earnings Call Transcript")
    parser.add_argument("--no-sec", action="store_true",
                        help="è·³è¿‡ SEC è´¢æŠ¥ä¸‹è½½")
    args = parser.parse_args()

    ticker = args.ticker.upper()
    download_dir = Path("downloads")
    ticker_folder = download_dir / ticker

    sec_files = []
    earnings_date = None

    try:
        # ä¸‹è½½ SEC è´¢æŠ¥ (10-K, 10-Q)
        if not args.no_sec:
            ticker_folder, sec_files = download_and_convert(ticker, download_dir)

        # ä¸‹è½½ Earnings Call Transcript
        if args.earnings:
            from earnings import download_earnings_transcript, search_transcript_from_quote_page, search_transcript_from_index, download_transcript_page

            # è·å–æ—¥æœŸä¿¡æ¯
            url = search_transcript_from_quote_page(ticker)
            if not url:
                url = search_transcript_from_index(ticker)
            if url:
                _, metadata = download_transcript_page(url)
                earnings_date = metadata.get("date")

            ticker_folder = download_earnings_transcript(ticker, download_dir)

        # æ‰“å°æŠ¥å‘Šæ—¶é—´æ‘˜è¦
        print_report_summary(sec_files, earnings_date)

        open_folder(ticker_folder)
        show_prompt()
    except Exception as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
